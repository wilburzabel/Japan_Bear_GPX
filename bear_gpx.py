import streamlit as st
import folium
from streamlit_folium import st_folium
import pandas as pd
import gpxpy
import requests
from geopy.distance import geodesic
from folium.plugins import MarkerCluster
from datetime import datetime, timedelta

st.set_page_config(page_title="æ—¥æœ¬ç†Šå‡ºæ²¡ (äº‘ç«¯ç‰ˆ)", layout="wide")
st.title("ðŸ» æ—¥æœ¬ç†Šå‡ºæ²¡åœ°å›¾ (äº‘ç«¯éƒ¨ç½²ç‰ˆ)")

# --- 1. ä»Ž Secrets è¯»å– Cookie (æ›´å®‰å…¨) ---
def get_headers_from_secrets():
    """ä»Ž Streamlit åŽå°é…ç½®è¯»å– Cookieï¼Œé˜²æ­¢ä»£ç æ³„éœ²"""
    try:
        # å¿…é¡»åœ¨ Streamlit Cloud åŽå°è®¾ç½®è¿™äº› secrets
        return {
            'cookies': {
                'XSRF-TOKEN': st.secrets["kumadas_cookies"]["XSRF_TOKEN"],
                '_session': st.secrets["kumadas_cookies"]["SESSION"],
                # å…¶ä»–å¿…è¦çš„ cookie...
            },
            'headers': {
                'x-csrf-token': st.secrets["kumadas_headers"]["CSRF_TOKEN"],
                'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) ...',
                'content-type': 'application/json',
                'origin': 'https://kumadas.net',
                'referer': 'https://kumadas.net/'
            }
        }
    except Exception:
        return None

# --- 2. æ•°æ®æŠ“å–é€»è¾‘ ---
@st.cache_data(ttl=300)
def fetch_online_data(start_date, end_date):
    # å°è¯•è¯»å– Secrets
    config = get_headers_from_secrets()
    
    if not config:
        st.error("âŒ æœªé…ç½® Secretsï¼è¯·åœ¨ Streamlit åŽå°å¡«å…¥ Cookieã€‚")
        return None

    url = 'https://kumadas.net/api/ver1/sightings/post_list'
    
    json_data = {
        'lat': 38.00, 'lng': 137.00,
        'filter': {
            'radius': '3000',
            'info_type_ids': ['1', '2', '3', '4'],
            'animal_species_ids': ['1'],
            'municipality_ids': [],
            'startdate': start_date.strftime("%Y-%m-%d"),
            'enddate': end_date.strftime("%Y-%m-%d"),
        },
    }

    try:
        resp = requests.post(
            url, 
            cookies=config['cookies'], 
            headers=config['headers'], 
            json=json_data, 
            timeout=20
        )
        if resp.status_code == 200:
            items = resp.json()
            if isinstance(items, dict): items = items.get('data', [])
            
            cleaned = []
            for item in items:
                lat = item.get('lat') or item.get('latitude')
                lon = item.get('lng') or item.get('longitude')
                d_str = item.get('sighted_at') or item.get('created_at')
                if lat and lon and d_str:
                    cleaned.append({
                        "date": d_str, # å…ˆå­˜å­—ç¬¦ä¸²ï¼ŒåŽé¢è½¬
                        "lat": float(lat),
                        "lon": float(lon),
                        "desc": item.get('body', 'æ— æè¿°'),
                        "place": item.get('place_name', '')
                    })
            return pd.DataFrame(cleaned)
    except Exception as e:
        st.error(f"è¿žæŽ¥é”™è¯¯: {e}")
    return None

# --- 3. GPX è§£æž ---
def parse_gpx(file):
    try:
        gpx = gpxpy.parse(file)
        return [(p.latitude, p.longitude) for t in gpx.tracks for s in t.segments for p in s.points]
    except: return []

# --- 4. ä¸»ç•Œé¢é€»è¾‘ ---

# ä¾§è¾¹æ ï¼šé€‰æ‹©æ•°æ®æº
st.sidebar.header("ðŸ“¡ æ•°æ®æº")
data_mode = st.sidebar.radio("é€‰æ‹©æ¨¡å¼", ["åœ¨çº¿æŠ“å– (éœ€æœ‰æ•ˆCookie)", "ä¸Šä¼ åŽ†å²å¤‡ä»½ (ç¦»çº¿)"])

df_bears = pd.DataFrame()

if data_mode == "åœ¨çº¿æŠ“å– (éœ€æœ‰æ•ˆCookie)":
    s_date = st.sidebar.date_input("å¼€å§‹æ—¥æœŸ", datetime.now().date() - timedelta(days=30))
    e_date = st.sidebar.date_input("ç»“æŸæ—¥æœŸ", datetime.now().date())
    
    if st.sidebar.button("å¼€å§‹æŠ“å–"):
        with st.spinner("æ­£åœ¨è¿žæŽ¥ Kumadas..."):
            df_bears = fetch_online_data(s_date, e_date)
            
        if df_bears is not None and not df_bears.empty:
            st.success(f"âœ… æˆåŠŸæŠ“å– {len(df_bears)} æ¡æ•°æ®ï¼")
            
            # âœ¨ å…³é”®ç‚¹ï¼šæä¾›ä¸‹è½½æŒ‰é’®æ¥å®žçŽ°â€œæŒä¹…åŒ–â€
            csv = df_bears.to_csv(index=False).encode('utf-8')
            st.sidebar.download_button(
                label="ðŸ’¾ ä¸‹è½½æ•°æ®å¤‡ä»½ (ä»¥ä¾¿ä¸‹æ¬¡ä½¿ç”¨)",
                data=csv,
                file_name='kumadas_backup.csv',
                mime='text/csv',
            )

elif data_mode == "ä¸Šä¼ åŽ†å²å¤‡ä»½ (ç¦»çº¿)":
    backup_file = st.sidebar.file_uploader("ðŸ“‚ ä¸Šä¼ ä¹‹å‰çš„ kumadas_backup.csv", type=['csv'])
    if backup_file:
        df_bears = pd.read_csv(backup_file)
        st.sidebar.success(f"å·²åŠ è½½ç¦»çº¿æ•°æ®: {len(df_bears)} æ¡")

# ç»Ÿä¸€å¤„ç†æ•°æ®
if not df_bears.empty:
    df_bears['date'] = pd.to_datetime(df_bears['date']).dt.date
    
    # åœ°å›¾å±•ç¤º (é™åˆ¶æ˜¾ç¤ºæ•°é‡é˜²æ­¢å¡é¡¿)
    m = folium.Map(location=[36.0, 138.0], zoom_start=5)
    mc = MarkerCluster().add_to(m)
    
    # åªæ˜¾ç¤ºæœ€è¿‘çš„ 1000 ä¸ªç‚¹ï¼Œé¿å…æµè§ˆå™¨å´©æºƒ
    for _, row in df_bears.head(1000).iterrows():
        folium.Marker(
            [row['lat'], row['lon']], 
            popup=f"{row['date']}\n{row['place']}",
            icon=folium.Icon(color='red', icon='paw', prefix='fa')
        ).add_to(mc)

    # GPX ä¸Šä¼ ä¸Žåˆ†æž
    gpx_file = st.sidebar.file_uploader("ä¸Šä¼  GPX æ£€æµ‹é£Žé™©", type=['gpx'])
    safe_dist = st.sidebar.slider("é£Žé™©åŠå¾„ (km)", 0.5, 5.0, 1.0)
    
    if gpx_file:
        pts = parse_gpx(gpx_file)
        if pts:
            folium.PolyLine(pts, color="blue", weight=4).add_to(m)
            
            # é£Žé™©è®¡ç®— (ä½¿ç”¨å…¨éƒ¨æ•°æ®)
            risks = []
            sampled_route = pts[::20] if len(pts) > 50 else pts
            for _, b in df_bears.iterrows():
                b_loc = (b['lat'], b['lon'])
                for r in sampled_route:
                    if geodesic(b_loc, r).km <= safe_dist:
                        risks.append(b)
                        break
            
            if risks:
                risk_df = pd.DataFrame(risks)
                st.error(f"âš ï¸ è·¯çº¿ä¸Šå‘çŽ° {len(risk_df)} ä¸ªé£Žé™©ç‚¹ï¼")
                st.dataframe(risk_df)
                for _, r in risk_df.iterrows():
                    folium.Circle([r['lat'], r['lon']], radius=safe_dist*1000, color='crimson', fill=True).add_to(m)
            else:
                st.success("âœ… è·¯çº¿å®‰å…¨")

    st_folium(m, width="100%", height=600)

else:
    st.info("ðŸ‘ˆ è¯·åœ¨å·¦ä¾§é€‰æ‹©æ¨¡å¼ï¼šå¦‚æžœCookieæœ‰æ•ˆåˆ™ã€åœ¨çº¿æŠ“å–ã€‘ï¼Œå¦‚æžœå¤±æ•ˆåˆ™ã€ä¸Šä¼ ã€‘ä¹‹å‰çš„å¤‡ä»½æ–‡ä»¶ã€‚")
