import streamlit as st
import folium
from streamlit_folium import st_folium
import pandas as pd
import gpxpy
import requests
import re
from datetime import datetime
from geopy.distance import geodesic
from folium.plugins import MarkerCluster

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="æ—¥æœ¬ç†Šå‡ºæ²¡åœ°å›¾ (TV Asahiç‰ˆ)", layout="wide")

st.title("ğŸ» æ—¥æœ¬ç†Šå‡ºæ²¡åœ°å›¾ - 2025ç‰¹åˆ«ç‰ˆ")
st.markdown("æ•°æ®æ¥æºï¼š[æœæ—¥ç”µè§†å° ç†Šå‡ºæ²¡ä¸“é¢˜](https://news.tv-asahi.co.jp/special/202506bear/) | è‡ªåŠ¨åŒæ­¥æœ€æ–° JSON æ•°æ®")

# --- 1. æ•°æ®è·å–ä¸è§£æ ---

@st.cache_data(ttl=3600)  # ç¼“å­˜1å°æ—¶
def load_tvasahi_data():
    url = "https://news.tv-asahi.co.jp/special/202506bear/sys/data.json"
    try:
        response = requests.get(url, timeout=10)
        if response.status_code != 200:
            st.error("æ— æ³•è¿æ¥åˆ°æ•°æ®æº")
            return pd.DataFrame()
        
        json_data = response.json()
        markers = json_data.get('marker', [])
        
        data = []
        # æ­£åˆ™è¡¨è¾¾å¼ç”¨äºä»æ ‡é¢˜æå–æ—¥æœŸï¼šä¾‹å¦‚ "ã€2025å¹´8æœˆ25æ—¥ã€‘..."
        date_pattern = re.compile(r"ã€(\d+)å¹´(\d+)æœˆ(\d+)æ—¥ã€‘")

        for item in markers:
            # 1. è¿‡æ»¤æ— æ•ˆæ•°æ® (è°ƒæ•´ç”¨Piné€šå¸¸çº¬åº¦å¾ˆé«˜æˆ–æ ‡é¢˜å«ç‰¹å®šè¯)
            if "èª¿æ•´ç”¨" in item.get('title', '') or float(item.get('latitude', 0)) > 80:
                continue

            # 2. æå–æ—¥æœŸ
            title = item.get('title', '')
            match = date_pattern.search(title)
            if match:
                try:
                    year, month, day = map(int, match.groups())
                    date_obj = datetime(year, month, day).date()
                except:
                    date_obj = None
            else:
                date_obj = None

            # 3. æ•´ç†æ•°æ®
            data.append({
                "date": date_obj,
                "title": title,
                "desc": item.get('description', ''),
                "lat": float(item.get('latitude')),
                "lon": float(item.get('longitude')),
                "url": item.get('link_url', '')
            })
            
        df = pd.DataFrame(data)
        # åˆ é™¤æ²¡æœ‰æ—¥æœŸçš„è„æ•°æ®
        df = df.dropna(subset=['date'])
        return df

    except Exception as e:
        st.error(f"æ•°æ®è§£æé”™è¯¯: {e}")
        return pd.DataFrame()

def parse_gpx(uploaded_file):
    """è§£æGPXæ–‡ä»¶"""
    if uploaded_file is not None:
        try:
            gpx = gpxpy.parse(uploaded_file)
            points = []
            for track in gpx.tracks:
                for segment in track.segments:
                    for point in segment.points:
                        points.append((point.latitude, point.longitude))
            return points
        except:
            st.error("GPXæ–‡ä»¶è§£æå¤±è´¥")
    return []

def check_proximity(route_points, bear_df, threshold_km=1.0):
    """æ£€æµ‹è·¯çº¿é£é™©"""
    dangers = []
    # æŠ½æ ·æ£€æŸ¥è·¯çº¿ç‚¹ä»¥æé«˜é€Ÿåº¦ (æ¯50ä¸ªç‚¹æŸ¥ä¸€æ¬¡)
    sampled_route = route_points[::50] 
    
    # å¦‚æœè·¯çº¿ç‚¹å¤ªå°‘ï¼Œå°±å…¨éƒ¨æ£€æŸ¥
    if len(route_points) < 50:
        sampled_route = route_points

    for _, bear in bear_df.iterrows():
        bear_loc = (bear['lat'], bear['lon'])
        for route_pt in sampled_route:
            if geodesic(bear_loc, route_pt).km <= threshold_km:
                dangers.append(bear)
                break
    return pd.DataFrame(dangers)

# --- 2. ç¨‹åºä¸»é€»è¾‘ ---

# åŠ è½½æ•°æ®
with st.spinner("æ­£åœ¨ä»æœæ—¥ç”µè§†å°æœåŠ¡å™¨è·å–æœ€æ–°æ•°æ®..."):
    df_bears = load_tvasahi_data()

if df_bears.empty:
    st.warning("æœªèƒ½è·å–åˆ°æ•°æ®ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚")
    st.stop()

# ä¾§è¾¹æ æ§åˆ¶
st.sidebar.header("ğŸ“… ç­›é€‰ä¸è®¾ç½®")

# æ—¥æœŸæ»‘å—
min_date = df_bears['date'].min()
max_date = df_bears['date'].max()

start_date, end_date = st.sidebar.date_input(
    "é€‰æ‹©æ—¶é—´èŒƒå›´",
    [min_date, max_date],
    min_value=min_date,
    max_value=max_date
)

# æ ¹æ®æ—¥æœŸè¿‡æ»¤
filtered_data = df_bears[
    (df_bears['date'] >= start_date) & 
    (df_bears['date'] <= end_date)
]

st.sidebar.success(f"æ˜¾ç¤ºè®°å½•: {len(filtered_data)} / {len(df_bears)} æ¡")

# GPX ä¸Šä¼ 
uploaded_file = st.sidebar.file_uploader("ğŸ“‚ ä¸Šä¼ GPXè·¯çº¿æ–‡ä»¶", type=['gpx'])
safe_distance = st.sidebar.slider("ğŸ”´ è­¦æˆ’åŠå¾„ (km)", 0.5, 5.0, 1.0)

# --- 3. åœ°å›¾ç»˜åˆ¶ ---

# é»˜è®¤ä¸­å¿ƒè®¾ä¸ºæœ€æ–°çš„ä¸€ä¸ªç‚¹ï¼Œæˆ–è€…æ—¥æœ¬ä¸­å¿ƒ
if not filtered_data.empty:
    center_lat = filtered_data.iloc[0]['lat']
    center_lon = filtered_data.iloc[0]['lon']
else:
    center_lat, center_lon = 36.2048, 138.2529 # æ—¥æœ¬å¤§æ¦‚ä¸­å¿ƒ

m = folium.Map(location=[center_lat, center_lon], zoom_start=6, tiles="OpenStreetMap")

# ç»˜åˆ¶ç†Šç‚¹ (ä½¿ç”¨èšç±»æ’ä»¶é˜²æ­¢å¡é¡¿)
marker_cluster = MarkerCluster().add_to(m)

for _, row in filtered_data.iterrows():
    # æ„å»ºå¼¹å‡ºå†…å®¹
    popup_html = f"""
    <b>æ—¥æœŸ:</b> {row['date']}<br>
    <b>åœ°ç‚¹:</b> {row['title']}<br>
    <div style='width:200px; white-space:normal;'>{row['desc']}</div>
    """
    
    folium.Marker(
        location=[row['lat'], row['lon']],
        popup=folium.Popup(popup_html, max_width=300),
        icon=folium.Icon(color="red", icon="paw", prefix='fa')
    ).add_to(marker_cluster)

# GPX è·¯çº¿ä¸é£é™©åˆ†æ
danger_bears = pd.DataFrame()

if uploaded_file:
    route_points = parse_gpx(uploaded_file)
    if route_points:
        # ç”»è·¯çº¿
        folium.PolyLine(route_points, color="blue", weight=5, opacity=0.7).add_to(m)
        
        # è°ƒæ•´è§†è§’åˆ°è·¯çº¿èµ·ç‚¹
        m.location = route_points[0]
        m.zoom_start = 12
        
        # è®¡ç®—é£é™©
        danger_bears = check_proximity(route_points, filtered_data, safe_distance)
        
        # é«˜äº®å±é™©ç†Šç‚¹
        if not danger_bears.empty:
            for _, row in danger_bears.iterrows():
                folium.Circle(
                    location=[row['lat'], row['lon']],
                    radius=safe_distance * 1000,
                    color="crimson",
                    fill=True,
                    fill_opacity=0.3,
                    popup="âš ï¸ è­¦æˆ’ï¼šè·¯çº¿ä¸Šæœ‰ç†Š"
                ).add_to(m)

# --- 4. æ˜¾ç¤ºç•Œé¢ ---

col1, col2 = st.columns([3, 1])

with col1:
    st_folium(m, width="100%", height=700)

with col2:
    st.subheader("ğŸ“Š é£é™©åˆ†ææŠ¥å‘Š")
    
    if uploaded_file:
        if not danger_bears.empty:
            st.error(f"âš ï¸ è­¦å‘Šï¼è·¯çº¿ä¸Šå‘ç° {len(danger_bears)} å¤„é£é™©è®°å½•ï¼")
            st.markdown(f"**è­¦æˆ’åŠå¾„ {safe_distance}km å†…çš„ç›®å‡»è®°å½•ï¼š**")
            
            for _, row in danger_bears.iterrows():
                with st.expander(f"{row['date']} - {row['title'][:10]}..."):
                    st.write(row['desc'])
                    if row['url']:
                        st.markdown(f"[æŸ¥çœ‹æ–°é—»é“¾æ¥]({row['url']})")
        else:
            st.success("âœ… æ‚¨çš„è·¯çº¿åœ¨æ‰€é€‰æ—¶é—´æ®µå†…ç›¸å¯¹å®‰å…¨ã€‚")
    else:
        st.info("ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼  GPX æ–‡ä»¶ä»¥æ£€æµ‹è·¯çº¿å®‰å…¨ã€‚")
        
    st.markdown("---")
    st.markdown("### æœ€è¿‘5æ¡å…¨å¢ƒè®°å½•")
    # æ˜¾ç¤ºæœ€è¿‘çš„å‡ æ¡è®°å½•ä¾›å‚è€ƒ
    recent = filtered_data.sort_values(by='date', ascending=False).head(5)
    for _, row in recent.iterrows():
        st.text(f"{row['date']} {row['title'][:15]}...")