import streamlit as st
import streamlit.components.v1 as components 
import pandas as pd
import requests
import gpxpy
from shapely.geometry import Point, LineString
import folium
import datetime

# ==========================================
# 0. é¡µé¢é…ç½®
# ==========================================
st.set_page_config(page_title="ç†Šå‡ºæ²¡åœ°å›¾ (å…¨é‡æ•°æ®ç‰ˆ)", layout="wide", page_icon="ğŸ»")
st.title("ğŸ» ç†Šå‡ºæ²¡å®‰å…¨åœ°å›¾ (2022-2025 å…¨é‡æ•°æ®)")

# ==========================================
# 1. æ•°æ®æŠ½å– (åˆå¹¶ä¸‰ä¸ªå¹´åº¦)
# ==========================================
@st.cache_data
def load_yamanashi_data():
    url = "https://catalog.dataplatform-yamanashi.jp/api/action/datastore_search"
    
    # è¿™é‡Œçš„åˆ—è¡¨åŒ…å«äº†ä½ æä¾›çš„æ‰€æœ‰ ID
    resource_ids = [
        "b4eb262f-07e0-4417-b24f-6b15844b4ac1", # 2024-2025 (æœ€æ–°)
        "62796404-c80f-47d6-ae88-222f844ee958", # 2023 (å†å²)
        "89d2478e-e29e-46e3-9ad3-19bf44822d4d"  # 2022 (å†å²)
    ]
    
    all_frames = []
    
    # å¾ªç¯è·å–æ‰€æœ‰ ID çš„æ•°æ®
    for rid in resource_ids:
        params = {"resource_id": rid, "limit": 10000} # ç¡®ä¿æ‹¿å…¨
        try:
            response = requests.get(url, params=params, timeout=10)
            data = response.json()
            
            if 'result' in data and 'records' in data['result']:
                df = pd.DataFrame(data['result']['records'])
                
                # å­—æ®µåæ˜ å°„ (æ¶µç›–ä¸åŒå¹´ä»½å¯èƒ½çš„å†™æ³•)
                rename_map = {
                    'ç·¯åº¦': 'latitude', 'çº¬åº¦': 'latitude', 'Lat': 'latitude', 'LAT': 'latitude',
                    'çµŒåº¦': 'longitude', 'ç»åº¦': 'longitude', 'Lon': 'longitude', 'LON': 'longitude',
                    'å¹´æœˆæ—¥': 'sighting_datetime', 'ç™ºç”Ÿæ—¥æ™‚': 'sighting_datetime', 'Date': 'sighting_datetime'
                }
                df = df.rename(columns=rename_map)
                
                # å¿…é¡»æœ‰ç»çº¬åº¦
                if 'latitude' in df.columns and 'longitude' in df.columns:
                    df['latitude'] = pd.to_numeric(df['latitude'], errors='coerce')
                    df['longitude'] = pd.to_numeric(df['longitude'], errors='coerce')
                    df = df.dropna(subset=['latitude', 'longitude'])
                    
                    # æ—¶é—´è½¬æ¢
                    if 'sighting_datetime' in df.columns:
                        df['sighting_datetime'] = pd.to_datetime(df['sighting_datetime'], errors='coerce')
                    else:
                        df['sighting_datetime'] = pd.NaT

                    # æè¿°å­—æ®µæ„å»º
                    def make_description(row):
                        parts = []
                        # ä¸åŒå¹´ä»½å­—æ®µåå¯èƒ½ä¸åŒï¼Œå°è¯•æ‰€æœ‰å¯èƒ½æ€§
                        possible_cols = ['ç›®æ’ƒå¸‚ç”ºæ‘', 'å ´æ‰€', 'ä½æ‰€', 'è©³ç´°', 'çŠ¶æ³', 'Municipality', 'Place']
                        for col in possible_cols:
                            val = str(row.get(col, ''))
                            if val and val != 'nan':
                                parts.append(val)
                        return " ".join(parts) if parts else "æ— æè¿°"
                    
                    df['sighting_condition'] = df.apply(make_description, axis=1)
                    
                    # ç»Ÿä¸€åˆ—ç»“æ„
                    clean_df = df[['latitude', 'longitude', 'sighting_datetime', 'sighting_condition']]
                    all_frames.append(clean_df)
                    
        except Exception as e:
            print(f"ID {rid} åŠ è½½å¤±è´¥: {e}")
            continue

    if all_frames:
        final_df = pd.concat(all_frames, ignore_index=True)
        return final_df
    else:
        return pd.DataFrame()

# åŠ è½½æ•°æ®
all_bears = load_yamanashi_data()
if all_bears.empty:
    st.error("âŒ æ•°æ®åº“åŠ è½½å¤±è´¥")
    st.stop()

# ==========================================
# 2. ç•Œé¢å¸ƒå±€
# ==========================================
col1, col2 = st.columns([3, 1])

with col1:
    uploaded_file = st.file_uploader("ğŸ“‚ ä¸Šä¼  GPX è·¯çº¿æ–‡ä»¶", type=['gpx'])

with col2:
    st.subheader("âš™ï¸ æ£€æµ‹è®¾ç½®")
    buffer_radius_m = st.slider("é¢„è­¦è·ç¦» (ç±³)", 100, 5000, 500, 100)
    
    # æ˜¾ç¤ºæ•°æ®ç»Ÿè®¡
    if not all_bears.empty:
        min_date = all_bears['sighting_datetime'].min().strftime('%Y-%m')
        max_date = all_bears['sighting_datetime'].max().strftime('%Y-%m')
        st.info(f"ğŸ“š æ•°æ®åº“è¦†ç›–: {min_date} è‡³ {max_date}\næ€»è®°å½•æ•°: {len(all_bears)}")
    
    st.divider()

# ==========================================
# 3. å¤„ç†é€»è¾‘
# ==========================================
map_html = ""
danger_list = []
points_count = 0

if uploaded_file:
    try:
        gpx = gpxpy.parse(uploaded_file)
        points = []
        for track in gpx.tracks:
            for segment in track.segments:
                for point in segment.points:
                    points.append((point.latitude, point.longitude))
        if not points:
            for route in gpx.routes:
                for point in route.points:
                    points.append((point.latitude, point.longitude))
        
        points_count = len(points)
        
        if points_count > 0:
            # åœ°å›¾ä¸­å¿ƒ
            start_lat, start_lon = points[0]
            m = folium.Map(location=[start_lat, start_lon], zoom_start=12, tiles="OpenStreetMap")
            
            # ç”»è·¯çº¿ (è“çº¿)
            folium.PolyLine(points, color="blue", weight=5, opacity=0.7).add_to(m)
            
            # ç¼“å†²åŒºè®¡ç®—
            line_points = [(p[1], p[0]) for p in points]
            route_line = LineString(line_points)
            deg_buffer = buffer_radius_m / 90000.0
            route_buffer = route_line.buffer(deg_buffer)
            
            # ç²—ç­›
            min_x, min_y, max_x, max_y = route_buffer.bounds
            candidates = all_bears[
                (all_bears['longitude'] >= min_x - 0.05) & 
                (all_bears['longitude'] <= max_x + 0.05) &
                (all_bears['latitude'] >= min_y - 0.05) & 
                (all_bears['latitude'] <= max_y + 0.05)
            ]
            
            # ç²¾ç­›ä¸ç»˜å›¾
            for idx, row in candidates.iterrows():
                b_lat = float(row['latitude'])
                b_lon = float(row['longitude'])
                bear_pt = Point(b_lon, b_lat)
                
                if route_buffer.contains(bear_pt):
                    danger_list.append(row)
                    
                    # çº¢ç‚¹é«˜äº®
                    folium.Marker(
                        location=[b_lat, b_lon],
                        popup=f"âš ï¸ {str(row['sighting_datetime'])[:10]}",
                        icon=folium.Icon(color='red', icon='info-sign')
                    ).add_to(m)
            
            m.fit_bounds(route_line.bounds)
            map_html = m._repr_html_()
            
        else:
            st.warning("GPX è§£ææˆåŠŸä½†æ— åæ ‡ç‚¹ã€‚")
            
    except Exception as e:
        st.error(f"å¤„ç†æŠ¥é”™: {
